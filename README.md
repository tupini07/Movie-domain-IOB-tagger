# Spoken Language Understanding Module for Movie Domain

This is the code and report done for the Language Understanding midterm project at UNITN 2018. The project consists of creating a language Understanding module that is capable of predicting the IOB tags of a given sentence, more information on the problem and methods used can be found in the [report](https://github.com/tupini07/Movie-domain-IOB-tagger/blob/master/report/report.pdf). 

The repository is divided into the following parts: 

- **p1_data** - contains the data used for training and evaluating the model. This folder also contains the [`conlleval`](https://github.com/tupini07/Movie-domain-IOB-tagger/blob/master/P1_data/scripts/conlleval.pl) script which is the one we use to obtain the performance metrics of the models. 
- **report folder** - it contains the latex source for the report, the graphics used and the PDF version of the report itself. 
- **P1-specification.pdf file** - describes the problem and objectives to be accomplished for this project. 
- **scripts folder** - contains the actual code for generating the models and graphics. The different modules are described below.

## Modules

The code is separated in the following python files:

- [`helper.py`](https://github.com/tupini07/Movie-domain-IOB-tagger/blob/master/scripts/helper.py) - module contains functions to load and process the dataset
- [`model.py`](https://github.com/tupini07/Movie-domain-IOB-tagger/blob/master/scripts/model.py) - file contains the functionality to create the different models
- [`scores.py`](https://github.com/tupini07/Movie-domain-IOB-tagger/blob/master/scripts/scores.py) - file contains functionality to evaluate the performance of the models on the test set
- [`bash.py`](https://github.com/tupini07/Movie-domain-IOB-tagger/blob/master/scripts/bash.py) - is just a wrapper that lets us call bash commands from within python
- [`main.py`](https://github.com/tupini07/Movie-domain-IOB-tagger/blob/master/scripts/main.py) - contains the main loop for the program, it's mainly dedicated to doing a grid search for the different parameters of the models and calculating its performance

An extra file, [`Graphics.ipynb`](https://github.com/tupini07/Movie-domain-IOB-tagger/blob/master/scripts/Graphics.ipynb), is a Jupyter notebook that creates the images used in the report. A notebook was chosen for this task since it provides immediate visual feedback, which makes it easier to debug and test different plots.

The scripts folder also contains 3 folders:

- `w/` - is the working directory in which a number of different files are created during execution. This is a small description of the most important files that are being created here:
    - `baseline_wfst_ngrm.fsa`, `iob_tagger_trans.fsa` and `iob_and_w_tagger_trans.fsa` are the `.fst` representation of the baseline, basic and improved models respectively.
    - The `lex.syms` file contains the lexicon file
    - `prediction_on_sent.txt` and `pred_coneval.txt` contain the predictions made for a specific sentence and the predictions made over all the test set respectively.

- `draw/` - This folder is intended to hold images generated during the execution. This is especially useful when debugging an `.fst` since we can easily represent it as an image. This folder is currently not being used in the code.

- `scores/` - This folder contains multiple score files generated by the conlleval script. Basically, for every tested model there is one score file. As it currently is, the program won't evaluate a model with X parameters if there is already a score file for it.


## How to run

The first thing you need to do to run this code is installing the dependencies. The project relies heavily on the [OpenFst](http://openfst.org/) and [OpenGrm](http://opengrm.org/) libraries so you'll need to install those. The source and compilation instructions can be found in the respective web pages, just note that OpenGrm depends on OpenFst so you must install it first, and make sure that you pass `--enable-far=yes` during the configuration step of OpenFst (this is needed for OpenGrm to work correctly). 

Then you need to install the following python packages:

- pandas - for reading and managing score files 
- tqdm - which provides a nice progress bar and ETA while calculating the scores
- nltk - provides an easy wat to calculate conditional frequencies
- seaborn - to generate the graphs used in the report

*Note: the program won't recalculate the scores for a model and it's parameters if there is already one said score file in the scores folder. The program checks the filename which is formatted as `<kind of model>_method-<method>_oder-<n-gram length>.txt` to check if a combination has already been executed. So, if you wish to recalculate the scores for a certain model you'll need to delete it's corresponding score file.*


## License 

MIT License

Copyright (c) 2018 Andrea Tupini

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.